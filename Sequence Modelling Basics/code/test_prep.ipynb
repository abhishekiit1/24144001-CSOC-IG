{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "d28a95ac",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "   polarity                                              title  \\\n",
      "0         2                                           Great CD   \n",
      "1         2  One of the best game music soundtracks - for a...   \n",
      "2         1                   Batteries died within a year ...   \n",
      "3         2              works fine, but Maha Energy is better   \n",
      "4         2                       Great for the non-audiophile   \n",
      "\n",
      "                                              review  \n",
      "0  My lovely Pat has one of the GREAT voices of h...  \n",
      "1  Despite the fact that I have only played a sma...  \n",
      "2  I bought this charger in Jul 2003 and it worke...  \n",
      "3  Check out Maha Energy's website. Their Powerex...  \n",
      "4  Reviewed quite a bit of the combo players and ...  \n",
      "polarity\n",
      "2    200000\n",
      "1    200000\n",
      "Name: count, dtype: int64\n"
     ]
    }
   ],
   "source": [
    "import pandas as pd\n",
    "import torch\n",
    "from torch.utils.data import Dataset, DataLoader\n",
    "from collections import Counter\n",
    "import numpy as np\n",
    "import re\n",
    "\n",
    "# Load test.csv without header, assign column names explicitly\n",
    "df_test = pd.read_csv(r'C:\\Users\\abhis\\OneDrive\\Desktop\\week4\\data\\test.csv', header=None, names=['polarity', 'title', 'review'])\n",
    "\n",
    "# Check the first few rows to confirm loading\n",
    "print(df_test.head())\n",
    "\n",
    "# Check the distribution of polarity values\n",
    "print(df_test['polarity'].value_counts())\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "e2bb654d",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Filtered dataset shape: (400000, 3)\n",
      "polarity\n",
      "2    200000\n",
      "1    200000\n",
      "Name: count, dtype: int64\n"
     ]
    }
   ],
   "source": [
    "# Keep only polarity 1 (negative) and 2 (positive)\n",
    "df_test = df_test[df_test['polarity'].isin([1, 2])]\n",
    "\n",
    "# Drop rows with missing review text\n",
    "df_test = df_test.dropna(subset=['review'])\n",
    "\n",
    "# Check new shape and polarity distribution\n",
    "print(f\"Filtered dataset shape: {df_test.shape}\")\n",
    "print(df_test['polarity'].value_counts())\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "2af5016e",
   "metadata": {},
   "outputs": [],
   "source": [
    "import re\n",
    "\n",
    "def clean_text(text):\n",
    "    text = str(text).lower()\n",
    "    text = re.sub(r\"<.*?>\", \"\", text)  # Remove HTML tags\n",
    "    text = re.sub(r\"[^a-z0-9\\s.,!?']\", \" \", text)  # Keep only basic punctuation and alphanumerics\n",
    "    text = re.sub(r\"\\s+\", \" \", text).strip()\n",
    "    return text\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "fba705df",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "                                              review  \\\n",
      "0  My lovely Pat has one of the GREAT voices of h...   \n",
      "1  Despite the fact that I have only played a sma...   \n",
      "2  I bought this charger in Jul 2003 and it worke...   \n",
      "3  Check out Maha Energy's website. Their Powerex...   \n",
      "4  Reviewed quite a bit of the combo players and ...   \n",
      "\n",
      "                                      cleaned_review  \n",
      "0  my lovely pat has one of the great voices of h...  \n",
      "1  despite the fact that i have only played a sma...  \n",
      "2  i bought this charger in jul 2003 and it worke...  \n",
      "3  check out maha energy's website. their powerex...  \n",
      "4  reviewed quite a bit of the combo players and ...  \n"
     ]
    }
   ],
   "source": [
    "df_test['cleaned_review'] = df_test['review'].apply(clean_text)\n",
    "\n",
    "# Check a few cleaned reviews\n",
    "print(df_test[['review', 'cleaned_review']].head())\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "76b80340",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "                                              review  \\\n",
      "0  My lovely Pat has one of the GREAT voices of h...   \n",
      "1  Despite the fact that I have only played a sma...   \n",
      "2  I bought this charger in Jul 2003 and it worke...   \n",
      "3  Check out Maha Energy's website. Their Powerex...   \n",
      "4  Reviewed quite a bit of the combo players and ...   \n",
      "\n",
      "                                      cleaned_review  \n",
      "0  my lovely pat has one of the great voices of h...  \n",
      "1  despite the fact that i have only played a sma...  \n",
      "2  i bought this charger in jul 2003 and it worke...  \n",
      "3  check out maha energy's website. their powerex...  \n",
      "4  reviewed quite a bit of the combo players and ...  \n"
     ]
    }
   ],
   "source": [
    "df_test['cleaned_review'] = df_test['review'].apply(clean_text)\n",
    "\n",
    "# Check a few cleaned reviews\n",
    "print(df_test[['review', 'cleaned_review']].head())\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "be820e1d",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "                                      cleaned_review  review_length\n",
      "0  my lovely pat has one of the great voices of h...            104\n",
      "1  despite the fact that i have only played a sma...            134\n",
      "2  i bought this charger in jul 2003 and it worke...             54\n",
      "3  check out maha energy's website. their powerex...             32\n",
      "4  reviewed quite a bit of the combo players and ...             65\n",
      "\n",
      "Review length stats:\n",
      "count    400000.000000\n",
      "mean         74.673272\n",
      "std          42.671076\n",
      "min           2.000000\n",
      "25%          39.000000\n",
      "50%          66.000000\n",
      "75%         104.000000\n",
      "max         217.000000\n",
      "Name: review_length, dtype: float64\n"
     ]
    }
   ],
   "source": [
    "df_test['review_length'] = df_test['cleaned_review'].apply(lambda x: len(x.split()))\n",
    "\n",
    "print(df_test[['cleaned_review', 'review_length']].head())\n",
    "print(f\"\\nReview length stats:\\n{df_test['review_length'].describe()}\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "013dbaef",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "   review_length  length_bin\n",
      "0            104           3\n",
      "1            134           4\n",
      "2             54           1\n",
      "3             32           0\n",
      "4             65           2\n",
      "5             66           2\n",
      "6             78           2\n",
      "7             38           1\n",
      "8             57           2\n",
      "9            147           4\n",
      "\n",
      "Length bin counts:\n",
      "length_bin\n",
      "0    82367\n",
      "3    80234\n",
      "2    79983\n",
      "4    79304\n",
      "1    78112\n",
      "Name: count, dtype: int64\n"
     ]
    }
   ],
   "source": [
    "df_test['length_bin'] = pd.qcut(df_test['review_length'], q=5, labels=False)\n",
    "\n",
    "print(df_test[['review_length', 'length_bin']].head(10))\n",
    "print(\"\\nLength bin counts:\")\n",
    "print(df_test['length_bin'].value_counts())\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "fa728ec3",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Sampled polarity counts:\n",
      "polarity\n",
      "1    193368\n",
      "2    192399\n",
      "Name: count, dtype: int64\n",
      "\n",
      "Sampled length_bin counts:\n",
      "length_bin\n",
      "2    78555\n",
      "1    78112\n",
      "3    77318\n",
      "4    77016\n",
      "0    74766\n",
      "Name: count, dtype: int64\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\abhis\\AppData\\Local\\Temp\\ipykernel_12452\\1912657512.py:5: DeprecationWarning: DataFrameGroupBy.apply operated on the grouping columns. This behavior is deprecated, and in a future version of pandas the grouping columns will be excluded from the operation. Either pass `include_groups=False` to exclude the groupings or explicitly select the grouping columns after groupby to silence this warning.\n",
      "  sampled_df_test = df_test.groupby(['polarity', 'length_bin'], group_keys=False).apply(\n"
     ]
    }
   ],
   "source": [
    "sample_size = 400000  # total samples after sampling\n",
    "n_bins = df_test['length_bin'].nunique()\n",
    "samples_per_group = sample_size // (2 * n_bins)  # 2 classes * bins\n",
    "\n",
    "sampled_df_test = df_test.groupby(['polarity', 'length_bin'], group_keys=False).apply(\n",
    "    lambda x: x.sample(min(len(x), samples_per_group), random_state=42)\n",
    ").reset_index(drop=True)\n",
    "\n",
    "\n",
    "print(\"Sampled polarity counts:\")\n",
    "print(sampled_df_test['polarity'].value_counts())\n",
    "print(\"\\nSampled length_bin counts:\")\n",
    "print(sampled_df_test['length_bin'].value_counts())\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "35ee6f46",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Saved cleaned and sampled training data to data/cleaned_sampled_test.csv\n"
     ]
    }
   ],
   "source": [
    "from pathlib import Path\n",
    "\n",
    "# Ensure data folder exists\n",
    "Path(r\"C:\\Users\\abhis\\OneDrive\\Desktop\\week4\\data\").mkdir(parents=True, exist_ok=True)\n",
    "\n",
    "# Save cleaned and sampled dataset with necessary columns only\n",
    "sampled_df_test[['cleaned_review', 'title', 'polarity']].to_csv(\"data/cleaned_sampled_test.csv\", index=False)\n",
    "\n",
    "print(\"Saved cleaned and sampled training data to data/cleaned_sampled_test.csv\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "69814c4b",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Unique polarity values: [1 0]\n",
      "Polarity dtype: int64\n",
      "   polarity                                              title  \\\n",
      "0         1                                           Great CD   \n",
      "1         1  One of the best game music soundtracks - for a...   \n",
      "2         0                   Batteries died within a year ...   \n",
      "3         1              works fine, but Maha Energy is better   \n",
      "4         1                       Great for the non-audiophile   \n",
      "\n",
      "                                              review  \\\n",
      "0  My lovely Pat has one of the GREAT voices of h...   \n",
      "1  Despite the fact that I have only played a sma...   \n",
      "2  I bought this charger in Jul 2003 and it worke...   \n",
      "3  Check out Maha Energy's website. Their Powerex...   \n",
      "4  Reviewed quite a bit of the combo players and ...   \n",
      "\n",
      "                                      cleaned_review  review_length  \\\n",
      "0  my lovely pat has one of the great voices of h...            104   \n",
      "1  despite the fact that i have only played a sma...            134   \n",
      "2  i bought this charger in jul 2003 and it worke...             54   \n",
      "3  check out maha energy's website. their powerex...             32   \n",
      "4  reviewed quite a bit of the combo players and ...             65   \n",
      "\n",
      "   length_bin  \n",
      "0           3  \n",
      "1           4  \n",
      "2           1  \n",
      "3           0  \n",
      "4           2  \n",
      "Dataset size: 400000\n"
     ]
    }
   ],
   "source": [
    "df_test['polarity'] = df_test['polarity'].map({1: 0, 2: 1})  # map labels to 0 and 1 for BCE loss\n",
    "# Check unique values after mapping\n",
    "print(\"Unique polarity values:\", df_test['polarity'].unique())\n",
    "\n",
    "# Check dtype (should be int or float before tensor conversion)\n",
    "print(\"Polarity dtype:\", df_test['polarity'].dtype)\n",
    "\n",
    "print(df_test.head())\n",
    "print(f\"Dataset size: {len(df_test)}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "93469133",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0    [my, lovely, pat, has, one, of, the, great, vo...\n",
      "1    [despite, the, fact, that, i, have, only, play...\n",
      "2    [i, bought, this, charger, in, jul, 2003, and,...\n",
      "3    [check, out, maha, energy's, website., their, ...\n",
      "4    [reviewed, quite, a, bit, of, the, combo, play...\n",
      "Name: tokens, dtype: object\n"
     ]
    }
   ],
   "source": [
    "def simple_tokenizer(text):\n",
    "    text = text.lower().strip()\n",
    "    tokens = text.split()\n",
    "    return tokens\n",
    "\n",
    "df_test['tokens'] = df_test['cleaned_review'].apply(simple_tokenizer)\n",
    "\n",
    "print(df_test['tokens'].head())\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "3d5254fd",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pickle\n",
    "with open(r'C:\\Users\\abhis\\OneDrive\\Desktop\\week4\\Sequence Modelling Basics\\word2idx.pkl', 'rb') as f:\n",
    "    word2idx = pickle.load(f)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "e597aad0",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0    [21, 1961, 5995, 40, 26, 7, 2, 47, 2302, 7, 76...\n",
      "1    [922, 2, 378, 13, 4, 20, 53, 481, 5, 251, 2575...\n",
      "2    [4, 93, 8, 1933, 11, 1, 4007, 3, 10, 333, 796,...\n",
      "3    [584, 42, 1, 1, 4069, 86, 1, 1, 1, 1933, 213, ...\n",
      "4    [3294, 243, 5, 229, 7, 2, 4955, 1499, 3, 14, 5...\n",
      "Name: indexed_tokens, dtype: object\n"
     ]
    }
   ],
   "source": [
    "def tokens_to_indices(tokens):\n",
    "    return [word2idx.get(token, word2idx[\"<UNK>\"]) for token in tokens]\n",
    "\n",
    "# Apply it to test set\n",
    "df_test['indexed_tokens'] = df_test['tokens'].apply(tokens_to_indices)\n",
    "print(df_test['indexed_tokens'].head())\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "a5ec8dad",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0    [21, 1961, 5995, 40, 26, 7, 2, 47, 2302, 7, 76...\n",
      "1    [922, 2, 378, 13, 4, 20, 53, 481, 5, 251, 2575...\n",
      "2    [4, 93, 8, 1933, 11, 1, 4007, 3, 10, 333, 796,...\n",
      "3    [584, 42, 1, 1, 4069, 86, 1, 1, 1, 1933, 213, ...\n",
      "4    [3294, 243, 5, 229, 7, 2, 4955, 1499, 3, 14, 5...\n",
      "Name: padded_tokens, dtype: object\n"
     ]
    }
   ],
   "source": [
    "from tensorflow.keras.preprocessing.sequence import pad_sequences\n",
    "\n",
    "max_len = 150  # same as used in train\n",
    "\n",
    "df_test['padded_tokens'] = list(pad_sequences(df_test['indexed_tokens'], maxlen=max_len, padding='post', truncating='post'))\n",
    "print(df_test['padded_tokens'].head())\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "cf8f83c6",
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "from torch.utils.data import Dataset\n",
    "\n",
    "class ReviewDataset(Dataset):\n",
    "    def __init__(self, texts, labels):\n",
    "        self.texts = torch.tensor(np.array(texts), dtype=torch.long)\n",
    "        self.labels = torch.tensor(labels.values, dtype=torch.float32)\n",
    "\n",
    "    def __len__(self):\n",
    "        return len(self.labels)\n",
    "\n",
    "    def __getitem__(self, idx):\n",
    "        return self.texts[idx], self.labels[idx]\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "2140841c",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Test batch shapes: torch.Size([128, 150]) torch.Size([128])\n"
     ]
    }
   ],
   "source": [
    "# Create test dataset and dataloader\n",
    "test_dataset = ReviewDataset(df_test['padded_tokens'].tolist(), df_test['polarity'])\n",
    "test_loader = DataLoader(test_dataset, batch_size=128, shuffle=False)\n",
    "\n",
    "# Sanity check\n",
    "sample_test_batch = next(iter(test_loader))\n",
    "print(\"Test batch shapes:\", sample_test_batch[0].shape, sample_test_batch[1].shape)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a78b39be",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.9"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
